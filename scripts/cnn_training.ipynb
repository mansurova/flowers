{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) Training\n",
    "\n",
    "This training is based upon existing [courses](https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l05c04_exercise_flowers_with_data_augmentation_solution.ipynb) and [tutorials on classification](https://www.tensorflow.org/tutorials/images/classification) and [transfer learning](https://www.tensorflow.org/tutorials/images/transfer_learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:54:45.358972Z",
     "start_time": "2020-06-10T13:54:30.250510Z"
    }
   },
   "outputs": [],
   "source": [
    "# System modules\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "# Math modules\n",
    "import numpy as np\n",
    "\n",
    "# Machine-learning modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from augment_data import augment_images\n",
    "\n",
    "# Plotting Modules\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(name)s\\t[%(levelname)-8s] %(message)s')\n",
    "logger = logging.getLogger('CNN')\n",
    "\n",
    "logger.info('Tensorflow Version: %s' % tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:54:45.485972Z",
     "start_time": "2020-06-10T13:54:45.479978Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define classes\n",
    "classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Execute this Code only once because it will move the data into a new training and validation directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T11:44:17.985214Z",
     "start_time": "2020-06-10T11:43:35.328921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load images\n",
    "cwd = os.getcwd() # current working directory\n",
    "base_dir = os.path.join(cwd, 'data') # base image directory\n",
    "for cl in classes:\n",
    "    img_path = os.path.join(base_dir, 'flowers', 'train', cl)\n",
    "    logger.debug('img_path: %s', img_path)\n",
    "    images = glob(img_path + '/*.jpg')\n",
    "    logger.info(\"%s:\\t%s Images\" % (cl, len(images)))\n",
    "\n",
    "    # Split images into train an validation\n",
    "    train, val = train_test_split(images, test_size=.2)\n",
    "\n",
    "    # Move images into training directory\n",
    "    for t in train:\n",
    "        if not os.path.exists(os.path.join(base_dir, 'train', cl)):\n",
    "            os.makedirs(os.path.join(base_dir, 'train', cl))\n",
    "        shutil.move(t, os.path.join(base_dir, 'train', cl))\n",
    "\n",
    "    # Move images into validation directory\n",
    "    for v in val:\n",
    "        if not os.path.exists(os.path.join(base_dir, 'val', cl)):\n",
    "            os.makedirs(os.path.join(base_dir, 'val', cl))\n",
    "        shutil.move(v, os.path.join(base_dir, 'val', cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:54:46.910327Z",
     "start_time": "2020-06-10T13:54:46.902327Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the (augmented) images\n",
    "Geting an image generator with default settings (rotation, transformation, etc.) and plot 10 example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T20:39:13.793767Z",
     "start_time": "2020-06-10T20:39:07.917758Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "img_height, img_width = 150, 150\n",
    "IMG_SHAPE=(img_height, img_width, 3)\n",
    "\n",
    "train_image_generator = augment_images(train_dir, \n",
    "        batch_size=batch_size,\n",
    "        output_shape=(img_height, img_width),\n",
    "        rotation_range=45,\n",
    "        width_shift_range=.1,\n",
    "        height_shift_range=.1,\n",
    "        zoom_range=.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rescale=1./255)\n",
    "batch_image, batch_type = next(train_image_generator)\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    image, type = batch_image[i,:,:,:], batch_type[i]\n",
    "    plt.imshow(image)\n",
    "    plt.title(classes[int(type)])\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "plt.savefig('output/augmented_data.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model\n",
    "Using a deep neural network as model ([Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)) with multiple [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) and [MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layers.\n",
    "\n",
    "The convolutional filters are all using the \"SAME\" padding and [ReLu](https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu) [activation function](https://www.tensorflow.org/api_docs/python/tf/keras/activations).\n",
    "\n",
    "Layers in detail:\n",
    "1. Convolutional Part\n",
    "  1. 16 basic (3 x 3) convolutional filters (Conv2D layer) with a ReLu activation function\n",
    "  2. (2 x 2) MaxPooling2D layer with a ReLu activation function.\n",
    "2. [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer to randomly drop 20% of the activated neurons (during training only).\n",
    "3. Convolutional Part\n",
    "  1. 32 (3 x 3) Conv2D layer with a ReLu activation function for more detailed features.\n",
    "  2. (2 x 2) MaxPooling2D layer with a ReLu activation function.\n",
    "3. Convolutional Part\n",
    "  1. 64 (3 x 3) Conv2D layer with a ReLu activation function for complex features.\n",
    "  2. (2 x 2) MaxPooling2D layer with a ReLu activation function.\n",
    "8. [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer to randomly drop 20% of the activated neurons (during training only).\n",
    "9. [Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten) layer just flattens the 2D image (3D with colors) into a 1D list.\n",
    "10. [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer with 512 connected neurons\n",
    "11. [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer to randomly drop 20% of the activated neurons (during training only).\n",
    "12. [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) output layer with 5 connected neurons and a [softmax](https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax) activation function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:57:12.583554Z",
     "start_time": "2020-06-10T13:57:11.926390Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "            Conv2D(16, 3, padding='same', activation='relu', input_shape=IMG_SHAPE),\n",
    "            MaxPooling2D(),\n",
    "            Dropout(0.2),\n",
    "            Conv2D(32, 3, padding='same', activation='relu'),\n",
    "            MaxPooling2D(),\n",
    "            Conv2D(64, 3, padding='same', activation='relu'),\n",
    "            MaxPooling2D(),\n",
    "            Dropout(0.2),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(5, activation='softmax')\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model using the **optimizer** [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) (short for adaptive moment estimation, [Source](https://arxiv.org/abs/1412.6980)).\n",
    "It is updating the weigths adaptively ... **TODO: Explain more**\n",
    "\n",
    "As **loss function** the [SparseCategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) calculates the cross entropy between the categories (*\"Using from_logits=True is more numerically stable\"* [Source](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy)). **TODO: Explain more**\n",
    "\n",
    "\n",
    "Evaluating the model by calculating the [`accuracy`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy) **TODO: Move to evaluating model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:57:15.973130Z",
     "start_time": "2020-06-10T13:57:15.857604Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy',])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T13:57:29.361059Z",
     "start_time": "2020-06-10T13:57:28.865191Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_gen = augment_images(train_dir, \n",
    "                                batch_size, \n",
    "                                output_shape=(img_height, img_width),\n",
    "        width_shift_range=.1,\n",
    "        height_shift_range=.1,\n",
    "        zoom_range=.1,\n",
    ")\n",
    "val_data_gen = augment_images(val_dir, \n",
    "                              batch_size, \n",
    "                              output_shape=(img_height, img_width),\n",
    "        width_shift_range=.1,\n",
    "        height_shift_range=.1,\n",
    "        zoom_range=.1,\n",
    "        )\n",
    "\n",
    "total_train = train_data_gen.samples\n",
    "total_val = val_data_gen.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:23:29.720712Z",
     "start_time": "2020-06-10T13:57:30.437553Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=1 + total_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=1 + total_val // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T14:24:45.554437Z",
     "start_time": "2020-06-10T14:24:44.385886Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "plt.savefig('output/own_model_training.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T20:38:04.255157Z",
     "start_time": "2020-06-10T20:37:50.313154Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "data = next(val_data_gen)\n",
    "y_pred = model.predict(data, batch_size)\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    image, typ = data[0][i,:,:,:], data[1][i]\n",
    "    plt.imshow(image)\n",
    "    prediction = np.argmax(y_pred[i,:])\n",
    "    color = \"blue\" if prediction == int(typ) else \"red\"\n",
    "    plt.title(\"%s (%.2f%s)\" % (classes[prediction], \n",
    "                                100*y_pred[i,prediction], \n",
    "                                '%'),\n",
    "                 color=color)\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "plt.savefig('output/cnn_model_predictions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:05:50.571417Z",
     "start_time": "2020-06-10T18:05:41.359219Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('output/cnn_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:07:11.130431Z",
     "start_time": "2020-06-10T19:07:11.095411Z"
    }
   },
   "source": [
    "# Compare with pre-trained model\n",
    "Creating a second model based on neural nets trained on [ImageNet](http://image-net.org/).\n",
    "* Source: [Mobile Net](https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4)\n",
    "* Source: [ResNet](https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T19:35:10.975810Z",
     "start_time": "2020-06-10T19:15:11.349471Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "img_height, img_width = 224, 224\n",
    "IMG_SHAPE=(img_height, img_width, 3)\n",
    "\n",
    "#imagenet = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "#                                             include_top=False,\n",
    "#                                             weights='imagenet')\n",
    "#imagenet.trainable = False\n",
    "\n",
    "URL = [\n",
    "       (\"mobilenet\", \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"),\n",
    "       (\"resnet\", \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\")\n",
    "]\n",
    "\n",
    "imnet_model = {}\n",
    "for net_descr, net_url in URL:\n",
    "    feature_extractor = hub.KerasLayer(net_url,\n",
    "                                       trainable=False,\n",
    "                                       input_shape=IMG_SHAPE)\n",
    "    imnet_model[net_descr] = Sequential([\n",
    "                feature_extractor,\n",
    "                Dropout(0.2),\n",
    "                Dense(5, activation='softmax')\n",
    "                ])\n",
    "    imnet_model[net_descr].compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy',])\n",
    "    imnet_model[net_descr].summary()\n",
    "\n",
    "    train_data_gen = augment_images(train_dir, \n",
    "                                    batch_size, \n",
    "                                    output_shape=(img_height, img_width),\n",
    "                                    )\n",
    "    val_data_gen = augment_images(val_dir, \n",
    "                                  batch_size, \n",
    "                                  output_shape=(img_height, img_width),\n",
    "                                  )\n",
    "\n",
    "    epochs = 40\n",
    "    history = imnet_model[net_descr].fit(\n",
    "        train_data_gen,\n",
    "        steps_per_epoch=1 + train_data_gen.n // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_data_gen,\n",
    "        validation_steps=1 + val_data_gen.n // batch_size\n",
    "    )\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "    plt.savefig('/content/drive/My Drive/Flowers_Training/output/imagenet_model_training%s.png' % net_descr)\n",
    "\n",
    "    imnet_model[net_descr].save('/content/drive/My Drive/Flowers_Training/output/cnn_model_%s' % net_descr)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    data = next(val_data_gen)\n",
    "    y_pred = imnet_model[net_descr].predict(data[0], batch_size)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        image, typ = data[0][i,:,:,:], data[1][i]\n",
    "        plt.imshow(image)\n",
    "        prediction = np.argmax(y_pred[i,:])\n",
    "        color = \"blue\" if prediction == int(typ) else \"red\"\n",
    "        plt.title(\"%s (%.2f%s)\" % (classes[prediction], \n",
    "                                    100*y_pred[i,prediction], \n",
    "                                    '%'),\n",
    "                    color=color)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.savefig('/content/output/cnn_model_predictions_%s.png' % net_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
